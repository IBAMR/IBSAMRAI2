/*
 * File:        $URL: file:///usr/casc/samrai/repository/SAMRAI/tags/v-2-4-4/source/mesh/clustering/AsyncBergerRigoutsosNode.h $
 * Copyright:   (c) 1997-2008 Lawrence Livermore National Security, LLC
 * Revision:    $LastChangedRevision: 2132 $
 * Modified:    $LastChangedDate: 2008-04-14 14:51:47 -0700 (Mon, 14 Apr 2008) $
 * Description: Asynchronous Berger-Rigoutsos dendogram
 */

#ifndef included_mesh_AsyncBergerRigoutsosNode
#define included_mesh_AsyncBergerRigoutsosNode

#include "SAMRAI_config.h"

#include "IntVector.h"

#include "LayerEdgeSet.h"

#include "LayerNodeSet.h"

#include "PatchLevel.h"

#include "tbox/AsyncCommGroup.h"

#include "tbox/JobRelauncher.h"

#include "tbox/Pointer.h"

#include "tbox/Timer.h"

namespace SAMRAI {
namespace mesh {


/*!
 * @brief Node in the asynchronous Berger-Rigoutsos (BR)
 * dendogram.
 *
 * In mesh generation, the BR algorithm can be used to cluster
 * tagged cells into boxes.
 * This algorithm is described in Berger and Rigoutsos,
 * IEEE Trans. on Sys, Man, and Cyber (21)5:1278-1286.
 *
 * This class implements the BR algorithm to execute
 * in a non-recursive way, in order to improve parallel
 * efficiency over recursive implementations.
 * To facilitate a non-recursive implementation,
 * data in the recursive tree is maintained in a "BR dendogram",
 * nodes of which are instances of this class.
 *
 * Clarification on the uses of the word "node":
 * - Dendogram node: Node in the BR dendogram (this class).
 * - Graph node: Node in a box graph.  The box graph is the form
 *   of the outputs of this class.  Each output graph node
 *   corresponds to a box generated by the BR algorithm.
 * - Processor: MPI process id.  This is called a node in some
 *   context.  For clarity, we avoid this use of "node".
 *
 * Each dendogram node is associated with a candidate box,
 * an owner process coordinating distributed computations on the box
 * and a group of processors participating in those computations.
 * Should the candidate box be one of the final output boxes,
 * the owner also owns the graph node associated with the box.
 *
 * To use this class:
 * -# Construct an object of type CommonParams.
 * -# Construct the root node of the dendogram using the
 *    CommonParams object.
 * -# Finetune the algorithm settings using the methods under
 *    "Algorithm settings".
 * -# If needed, various non-algorithmic flags using set...()
 *    methods under "Methods for analysis and debugging".
 * -# Initiate the algorithm using runAlgorithm() in the
 *    job_relauncher parameter in the CommonParams object.
 * -# Get the output graph nodes and edges using methods under
 *    "Access to outputs".
 *
 * This class creates its output in a distributed nested-level
 * box-graph (DNBG) format.  The output is distributed over all
 * processes running the algorithm, with each process owning a
 * subset of the DNBG.
 * The 2 primary outputs of this implementation are:
 * -# Set of graph nodes containing input tags.  Each node
 *    corresponds to an output box.  See getNewNodes()
 *    and hier::LayerNodeSet<DIM>.
 * -# Connectivity between graph nodes on the tagged level
 *    and the new graph nodes.  See getNewCnect() and
 *    hier::LayerEdgeSet<DIM>.
 */

template<int DIM>
class AsyncBergerRigoutsosNode
   : public tbox::RelaunchableJob
{

public:

   /*!
    * @brief Shorthand for the box-graph node corresponding
    * to boxes.
    */
   typedef typename hier::LayerNodeSet<DIM>::Node GraphNode;

   //! @brief Shorthand for a container of graph-nodes.
   typedef typename hier::LayerNodeSet<DIM>::NodeContainer GraphNodeContainer;

   //! @brief Shorthand for a container of neighbor graph-nodes.
   typedef typename hier::LayerEdgeSet<DIM>::NabrContainer GraphNabrContainer;

   /*!
    * @brief Shortthand for the connectivity between two
    * sets of graph nodes.
    */
   typedef typename hier::LayerEdgeSet<DIM>::Connectivity Connectivity;

   //! @brief Shorthand for a sorted, possibly incontiguous, set of integers.
   typedef std::set<int> IntSet;


   enum OwnerMode { SINGLE_OWNER = 0 ,
                    MOST_OVERLAP = 1 ,
                    FEWEST_OWNED = 2 ,
                    LEAST_ACTIVE = 3 };


   /*!
    * @brief Parameters shared among all dendogram nodes in
    * an dendogram and collectively managed by those nodes.
    *
    * In the implementation of the BR algorithm, some parameters
    * are to be shared among all nodes in the dendogram,
    * either for efficiency or coordinating the dendogram nodes.
    * All such parameters are contained in a single CommonParams
    * object.
    */
   struct CommonParams {
      /*!
       * @brief Constructor sets all const members,
       * which must be given in argument.
       */
      CommonParams(
         const tbox::Pointer<hier::PatchLevel<DIM> > level_,
         const int tag_data_index_,
         const int tag_val_ ,
         const hier::IntVector<DIM> min_box_,
         const double efficiency_tol_,
         const double combine_tol_,
         const tbox::SAMRAI_MPI::comm mpi_communicator_);

      /*!
       * @brief Utility function for getting rank
       * from an arbitrary communicator.
       */

      static int getRank( const tbox::SAMRAI_MPI::comm &mpi_communicator_ );
      /*!
       * @brief Utility function for getting processor count
       * from an arbitrary communicator.
       */
      static int getProcCount( const tbox::SAMRAI_MPI::comm &mpi_communicator_ );

      tbox::JobRelauncher job_relauncher;


      /*!
       * @brief Layer of graph nodes coresponding to patch boxes
       * on the tagged level.
       *
       * If edges are computed (see setComputeEdges()), the edges
       * go between the graph nodes on the tagged level and the
       * generated graph nodes.
       */
      hier::LayerNodeSet<DIM> tag_node_set;

      /*!
       * @brief Layer of graph nodes (boxes) generated by BR.
       *
       * This is where we store the boxes resulting from the
       * BR algorithm.
       */
      hier::LayerNodeSet<DIM> new_node_set;

      /*!
       * @brief Connectivity from tag_node_set to new_node_set.
       *
       * This is where we store the edges resulting from the BR algorithm.
       * The edges are created locally for local nodes in tag_node_set.
       */
      Connectivity tag_cnect_new;

      /*!
       * @brief Connectivity from new_node_set to tag_node_set.
       *
       * The edges are created when the owners of nodes in tag_node_set
       * share edge data with owners of nodes in new_node_set.
       */
      Connectivity new_cnect_tag;

      /*!
       * @brief List of processes that will send neighbor data
       * for locally owned boxes after the BR algorithm completes.
       */
      IntSet edge_senders;

      /*!
       * @brief Outgoing messages to be sent to graph node owners
       * describing new edges found by local process.
       */
      std::map<int,std::vector<int> > edge_messages;

      //@{
      //@name Parameters from clustering algorithm interface
      const tbox::Pointer<hier::PatchLevel<DIM> > level;
      const int tag_data_index;
      const int tag_val ;
      const hier::IntVector<DIM> min_box;
      const double efficiency_tol;
      const double combine_tol;
      //@}

      /*!
       * @brief Edge computation flag.
       *
       * See setComputeEdges().
       */
      int compute_edges;

      //! @brief Ammount to grow a box when checking for overlap.
      hier::IntVector<DIM> max_gcw;

      //! @brief How to chose the group's owner.
      OwnerMode owner_mode;

      /*!
       * @brief Whether to use globally duplicated level boxes
       * and globally duplicate new graph nodes.
       */
      bool use_level_boxes;


      //@{
      //! @name Communication parameters
      /*!
       * @brief MPI communicator used in all communications in
       * the dendogram.
       *
       * Currently set to MPI_COMM_WORLD.  Could eventually be set
       * to a duplicate of MPI_COMM_WORLD if there is interference
       * with other communications using MPI_COMM_WORLD.
       */
      tbox::SAMRAI_MPI::comm mpi_communicator;
      const int rank;
      const int nproc;
      //! @brief Upperbound of valid tags.
      int tag_upper_bound;
      //! @brief Smallest unclaimed MPI tag in pool given to local process.
      int available_mpi_tag;
      //@}

      //@{
      //! @name Performance monitors
      tbox::Pointer<tbox::Timer> t_cluster;
      tbox::Pointer<tbox::Timer> t_continue_algorithm;
      tbox::Pointer<tbox::Timer> t_compute_new_graph_edges;
      tbox::Pointer<tbox::Timer> t_share_new_edges;
      tbox::Pointer<tbox::Timer> t_share_new_edges_send;
      tbox::Pointer<tbox::Timer> t_share_new_edges_recv;
      tbox::Pointer<tbox::Timer> t_share_new_edges_unpack;
      /*
       * Multi-stage timers.  These are used in continueAlgorithm()
       * instead of the methods they time, because what they time may
       * include waiting for messages.  They are included in the
       * timmer t_continue_algorithm.  They provide timing breakdown
       * for the different stages.
       */
      tbox::Pointer<tbox::Timer> t_reduce_histogram;
      tbox::Pointer<tbox::Timer> t_bcast_acceptability;
      tbox::Pointer<tbox::Timer> t_gather_grouping_criteria;
      tbox::Pointer<tbox::Timer> t_bcast_child_groups;
      tbox::Pointer<tbox::Timer> t_bcast_to_dropouts;
      //@}

      //@{
      //! @name Auxiliary data for analysis and debugging.

      //! @brief Whether to log major actions of dendogram node.
      bool log_node_history;
      //! @brief Current number of dendogram nodes allocated.
      int num_nodes_allocated;
      //! @brief Highest number of dendogram nodes.
      int max_nodes_allocated;
      //! @brief Current number of dendogram nodes active.
      int num_nodes_active;
      //! @brief Highest number of dendogram nodes active.
      int max_nodes_active;
      //! @brief Current number of dendogram nodes owned.
      int num_nodes_owned;
      //! @brief Highest number of dendogram nodes owned.
      int max_nodes_owned;
      //! @brief Current number of dendogram nodes completed.
      int num_nodes_completed;
      //! @brief Highest number of generation.
      int max_generation;
      //! @brief Current number of boxes generated.
      int num_boxes_generated;
      //! @brief Number of continueAlgorithm calls for to complete nodes.
      int num_conts_to_complete;
      //! @brief Highest number of continueAlgorithm calls to complete nodes.
      int max_conts_to_complete;
      //@}
   };

   /*!
    * @brief Construct a node of a BR dendogram.
    *
    * Construct a node node of a BR dendogram, which you can
    * use to run the BR algorithm.
    *
    * @param common_params The common parameter object you plan to
    *        use to run the ABR algorithm.
    * @param bound_box Bounding box for tagged cells.
    * @param parent Parent node of the node being constructed.
    *        Set to NULL if you are constructing the root node
    *        of the BR dendogram.
    * @param child_number 0 if constructing left child
    *        and 1 if constructing right child.
    *        Set to 1 if you are constructing the root node
    *        of the BR dendogram.
    */
   AsyncBergerRigoutsosNode(
      CommonParams *common_params,
      const hier::Box<DIM> *bound_box = NULL,
      mesh::AsyncBergerRigoutsosNode<DIM> *parent = NULL,
      const int child_number = 1 );

   /*!
    * @brief Destructor.
    *
    * Deallocate internal data.
    */
   ~AsyncBergerRigoutsosNode(void);



   //@{
   //! @name Algorithm mode settings

   /*!
    * @brief Set the maximum ghost cell width used for checking overlaps.
    *
    * Overlap checking is done to determine nearest-neighbor
    * relationships when generating connectivity to new graph nodes.
    * If a box grown by this ammount intersects another box,
    * the two boxes are considered neighbors.
    *
    * By default the max ghost cell width is one in each direction.
    */
   void setMaxGhostCellWidth( const hier::IntVector<DIM> &max_gcw );

   /*!
    * @brief Set the mode for advancing the asynchronous implementation.
    *
    * Choices are:
    * - @b "SYNCHRONOUS" --> wait for each communication stage to complete
    *   before moving on, thus resulting in synchronous execution.
    * - @b "ROUND_ROBIN" --> check for completed communication stages in
    *   round-robin fashion instead of waiting for a specific one.
    * - @b "ADVANCE_ANY" --> advance an dendogram node through its
    *   communication stage by using tbox::AsyncCommStage::advanceAny().
    * - @b "ADVANCE_SOME" --> advance an dendogram node through its
    *   communication stage by using tbox::AsyncCommStage::advanceSome().
    *
    * The default is "ADVANCE_SOME".
    *
    * Asynchronous modes are NOT guaranteed to compute the output
    * graph nodes in any particular order.  The order depends on
    * the ordering of message completion, which is not deterministic.
    * If you require consistent outputs, we suggest you have a scheme
    * for reordering the output boxes.
    */
   void setAlgorithmAdvanceMode( const std::string &algo_advance_mode );

   /*!
    * @brief Set the method for choosing the owner.
    * Choices:
    * - "MOST_OVERLAP"
    *   Ownership is given to the processor with the most
    *   overlap on the candidate box.  Default.
    * - "SINGLE_OWNER"
    *   In single-owner mode, the initial owner (process 0)
    *   always participates and owns all dendogram nodes.
    * - "FEWEST_OWNED"
    *   Choose the processor that owns the fewest dendogram
    *   nodes when the choice is made.  This is meant to
    *   relieve bottle-necks caused by excessive ownership.
    * - "LEAST_ACTIVE"
    *   Choose the processor that participates in the fewest
    *   number of dendogram nodes when the choice is made.
    *   This is meant to relieve bottle-necks caused by
    *   excessive participation.
    *
    * Experiments show that "MOST_OVERLAP" gives the best
    * clustering speed, while "SINGLE_OWNER" may give a faster
    * output globalization (since you don't need an all-gather).
    */
   void setOwnerMode( const std::string &mode );


   /*!
    * @brief Switch on or off the use of global level boxes
    *
    * If off, the global level boxes will neither be used nor
    * be generated.  This feature is in anticipation of future
    * support for the distributed nested-level box graph in SAMRAI.
    */
   void setUseLevelBoxes( bool flag );

   /*!
    * @brief Edge computation flag.
    *
    * Valid values to set are:
    * - 0 = No edge computation.
    * - 1 = Compute directed edges from input to output graph nodes.
    *       With this option, it is possible to determine output
    *       nodes neighboring any input nodes, but not possible to
    *       determine input nodes neighboring a specific output node.
    * - 2 = Compute directed edges from input to output graph nodes
    *       as well as the reverse.
    *       With this option, it is possible to determine output
    *       nodes neighboring any input nodes, as well as input nodes
    *       neighboring any output node.  This is accomplished using
    *       an additional edge-sharing communication after all
    *       graph nodes have been created.
    *
    * By default, the value is 2.
    */
   void setComputeEdges( int compute_edges );

   //@}

   /*!
    * @brief Run the BR algorithm to find boxes.
    */
   void runAlgorithm();


   //@{
   //! @name Access to outputs

   /*!
    * @brief Get the output boxes in a hier::LayerNodeSet<DIM> form.
    */
   const hier::LayerNodeSet<DIM> &getNewNodes() const;

   /*!
    * @brief Get the connectivity between input and output graph nodes
    * (between the tagged and new graph nodes).
    *
    * The connectivity data generated depend on the flag set using
    * setComputeEdges().
    */
   const Connectivity &getNewCnect() const;

   //@}


   //@{

   //! @name Developer's methods for analysis and debugging this class.
   virtual void printClassData( std::ostream &os, int detail_level=0 ) const;

   //! @brief Max number of local nodes for dendogram.
   int getMaxNodes() const;

   //! @brief max generation count for the local nodes in the dendogram.
   int getMaxGeneration() const;

   //! @brief Max number of locally owned nodes in the dendogram.
   int getMaxOwnership() const;

   //! @brief Average number of continuations for local nodes in dendogram.
   double getAvgNumberOfCont() const;

   //! @brief Max number of continuations for local nodes in dendogram.
   int getMaxNumberOfCont() const;

   /*!
    * @brief Number of boxes generated (but not necessarily owned)
    * on the local process.
    */
   int getNumBoxesGenerated() const;

   /*!
    * @brief Set whether to log dendogram node action history
    * (useful for debugging).
    */
   void setLogNodeHistory( bool flag );
   //@}



private:


   //@{
   //! @name Implementations for tbox::RelaunchableJob

   /*!
    * Continue the user-defined job.
    *
    * @return whether job finished.
    */
   virtual void continueJob();

   virtual JobState getJobState();

   virtual tbox::AsyncCommGroup *getCommunicationGroup();

   //@}



   /*!
    * @brief Names of algorithmic phases while outside of
    * continueAlgorithm().
    *
    * "For_data_only" phase is when the dendogram node is only used to
    * store data. If the node is to be executed, it enters the
    * "to_be_launched" phase.
    *
    * All names beginning with "reduce", "gather" or "bcast"
    * refer to communication phases, where control is
    * returned before the algorithm completes.
    *
    * The "children" phase does not explicitly contain communication,
    * but the children may perform communication.
    *
    * The "completed" phase is when the algorithm has run to completion.
    * This is where the recursive implementation would return.
    *
    * The "deallocated" phase is for debugging.  This phase is
    * set by the destructor, just to help find dendogram nodes that
    * are deallocated but somehow was referenced.
    */
   enum WaitPhase { for_data_only,
                    to_be_launched,
                    reduce_histogram,
                    bcast_acceptability,
                    gather_grouping_criteria,
                    bcast_child_groups,
                    run_children,
                    bcast_to_dropouts,
                    completed,
                    deallocated };

   /*!
    * @brief MPI tags identifying messages.
    *
    * Each message tag is the d_mpi_tag plus a PhaseTag.
    * Originally, there were different tags for different
    * communication phases, determined by d_mpi_tag plus
    * a PhaseTag.  But this is not really needed,
    * so all phases use the tag d_mpi_tag.  The PhaseTag
    * type is just here in case we have to go back to using
    * them.
    */
   enum PhaseTag { reduce_histogram_tag         = 0,
                   bcast_acceptability_tag      = 0,
                   gather_grouping_criteria_tag = 0,
                   bcast_child_groups_tag       = 0,
                   bcast_to_dropouts_tag        = 0,
                   total_phase_tags             = 1 };

   /*!
    * @brief Continue the the BR algorithm.
    *
    * Parameters for finding boxes are internal.
    * They should be set in the constructor.
    *
    * In parallel, this the method may return before
    * algorithm is completed.  In serial, no communication
    * is done, so the algorithm IS completed when this
    * method returns.  The method is completed if it
    * returns WaitPhase::completed.  This method may
    * and @em should be called multiple times as long as
    * the algorithm has not completed.
    *
    * If this method returns before the algorithm is
    * complete, this object will have put itself on
    * the leaf queue to be checked for completion later.
    *
    * @return The communication phase currently running.
    */
   WaitPhase continueAlgorithm();


   /*!
    * @brief Candidate box acceptance state.
    *
    * Note that accepted values are odd and rejected
    * and undetermined values are even!  See boxAccepted(),
    * boxRejected() and boxHasNoTag().
    *
    * It is not critical to have all values shown,
    * but the values help in debugging.
    *
    * Meaning of values:
    * - "hasnotag_by_owner": histogram is truly empty (after sum reduction).
    *   We don't accept the box, but we don't split it either.
    *   (This can only happen at the root dendogram node, as child
    *   boxes are guaranteed to have tags.)
    * - "(rejected|accepted)_by_calculation": decision by calculation
    *   on the owner process.
    * - "(rejected|accepted)_by_owner": decision by owner process,
    *   broadcast to participants.
    * - "(rejected|accepted)_by_recombination": decision by recombination
    *   on local process.
    * - "(rejected|accepted)_by_dropout_bcast": decision by participant group,
    *   broadcast
    *    to the dropout group.
    */
   enum BoxAcceptance { undetermined = -2,
                        hasnotag_by_owner = -1,
                        rejected_by_calculation = 0,
                        accepted_by_calculation = 1,
                        rejected_by_owner = 2,
                        accepted_by_owner = 3,
                        rejected_by_recombination = 4,
                        accepted_by_recombination = 5,
                        rejected_by_dropout_bcast = 6,
                        accepted_by_dropout_bcast = 7 };


   //@{
   //! @name Delegated tasks for various phases of running algorithm.
   void makeLocalTagHistogram();
   void reduceHistogram_start();
   bool reduceHistogram_check();
   void computeMinimalBoundingBoxForTags();
   void acceptOrSplitBox();
   void broadcastAcceptability_start();
   bool broadcastAcceptability_check();
   void countOverlapWithLocalPatches();
   void gatherGroupingCriteria_start();
   bool gatherGroupingCriteria_check();
   //! @brief Form child groups from gathered overlap counts.
   void formChildGroups();
   //! @brief Form child groups from local copy of all level boxes.
   void formChildGroupsUsingLevelBoxes();
   void broadcastChildGroups_start();
   bool broadcastChildGroups_check();
   void runChildren_start();
   bool runChildren_check();
   void broadcastToDropouts_start();
   bool broadcastToDropouts_check();
   void createLayerNode();
   void eraseLayerNode();
   //! @brief Compute new graph edges touching local tag nodes.
   void computeNewGraphEdges();
   //! @brief Participants send new edge data to graph node owners.
   void shareNewEdgesWithOwners();
   //@}

   //@{
   //! @name Utilities for implementing algorithm

   //! @brief Find the index of the owner in the group.
   int findOwnerInGroup( int owner, const tbox::Array<int> &group ) const;
   //! @brief Claim a unique tag from process's available tag pool.
   void claimMPITag();
   /*!
    * @brief Heuristically determine "best" tree degree for
    * communication group size.
    */
   int computeCommunicationTreeDegree( int group_size ) const;
   bool findZeroCutPoint( int &cut_pt,
                          const int dim);
   bool findZeroCutSwath( int &cut_lo,
                          int &cut_hi,
                          const int dim);

   void cutAtLaplacian( int &cut_pt, 
                        const int dim,
                        const int lo, 
                        const int hi, 
                        const int min_size);

   int getHistogramBufferSize( const hier::Box<DIM> &box ) const;
   int *putHistogramToBuffer( int *buffer );
   int *getHistogramFromBuffer( int *buffer );
   int *putBoxToBuffer( const hier::Box<DIM> &box, int *buffer ) const;
   int *getBoxFromBuffer( hier::Box<DIM> &box, int *buffer ) const;
   //! @brief Compute list of non-participating processes.
   void computeDropoutGroup( const tbox::Array<int> &main_group,
                             const tbox::Array<int> &sub_group,
                             tbox::Array<int> &dropouts,
                             const int add_group ) const;
   BoxAcceptance intToBoxAcceptance( int i ) const;
   bool boxAccepted() const { return bool(d_box_acceptance >= 0 &&
                                          d_box_acceptance % 2); };
   bool boxRejected() const { return bool(d_box_acceptance >= 0 &&
                                          d_box_acceptance % 2 == 0); };
   bool boxHasNoTag() const { return bool(d_box_acceptance == -1); };
   //@}

   //@{
   //! @name Utilities to help analysis and debugging
   tbox::List<tbox::RelaunchableJob*>::Iterator
   inRelaunchQueue( tbox::RelaunchableJob *node_ptr ) const;
   bool inGroup( tbox::Array<int> &group, int rank = -1 ) const;
   //@}



   /*!
    * @brief Unique id in the binary dendogram.
    *
    * - To have succinct formula, the root dendogram node has d_pos of 1.
    * - Parent id is d_pos/2
    * - Left child id is 2*d_pos
    * - Right child id is 2*d_pos+1
    * - Generation number is ln(d_pos)
    *
    * This parameter is only used for debugging.
    *
    * The id of a node grows exponentially with each generation.
    * If the position in the binary tree is too big to be represented
    * by an integer, d_pos is set to -1 for a left child and -2 for a
    * right child.
    */
   const int d_pos;

   /*!
    * @brief Common parameters shared with descendents and ancestors.
    *
    * Only the root of the tree allocates the common parameters.
    * For all others, this pointer is set by the parent.
    */
   CommonParams *d_common;

   //@{
   /*!
    * @name Tree-related data
    */

   //! @brief Parent node (or NULL for the root node).
   AsyncBergerRigoutsosNode *d_parent;

   //! @brief Left child.
   AsyncBergerRigoutsosNode *d_lft_child;

   //! @brief Right child.
   AsyncBergerRigoutsosNode *d_rht_child;

   //@}


   //@{
   /*!
    * @name Data for one recursion of the BR algorithm
    */

   /*
    * These parameters are listed roughly in order of usage.
    */

   hier::Box<DIM> d_box;
   int d_owner;

   /*!
    * @name Id of participating processes.
    */
   tbox::Array<int> d_group;

   /*!
    * @brief MPI tag for message within a dendogram node.
    *
    * The tag is determined by on the process that owns the parent
    * when the parent decides to split its box.  The tags are broadcasted
    * along with the children boxes.
    */
   int d_mpi_tag;

   /*!
    * @brief Overlap count with d_box.
    */
   int d_overlap;

   /*!
    * @brief Whether and how box is accepted.
    *
    * @see BoxAcceptance.
    */
   BoxAcceptance d_box_acceptance;

   /*!
    * @brief Histogram for all dimensions of box d_box.
    *
    * If local process is d_owner, this is initially the
    * local histogram, then later, the reduced histogram.
    * If not, it is just the local histogram.
    */
   tbox::Array<int> d_histogram[DIM];

   /*!
    * @brief Distributed graph node corresponding to an accepted box.
    *
    * On the owner process, this belongs in a hier::LayerNodeSet<DIM>
    * object.  On contributor nodes, this is used to identify
    * the layer node id assigned by the owner.  The layer node id
    * is important for computing neighbor data.
    */
   GraphNode d_node;

   /*!
    * @brief Distributed graph node iterator corresponding to
    * an accepted box on the owner.
    *
    * This is relevant only on the owner, where the d_node is
    * in a container.  On contributors, the graph node is non-local
    * and stands alone.
    */
   typename GraphNodeContainer::iterator d_node_iterator;

   /*!
    * @brief Name of wait phase when continueAlgorithm()
    * exits before completion.
    */
   WaitPhase d_wait_phase;

   //@}

   //@{
   /*!
    * @name Lower-level parameters for communication.
    */

   //! @brief Buffer for organizing outgoing data.
   tbox::Array<int> d_send_msg;
   //! @brief Buffer for organizing incoming data.
   tbox::Array<int> d_recv_msg;

   tbox::AsyncCommGroup *d_comm_group;
   //@}


   //@{
   //! @name Deubgging aid

   /*!
    * @brief Generation number.
    *
    * The generation number is the parent's generation number plus 1.
    * The root has generation number 1.
    */
   const int d_generation;

   //! @brief Number of times continueAlgorithm was called.
   int d_n_cont;

   //@}


};

}
}

#endif  // included_mesh::AsyncBergerRigoutsosNode

#ifdef INCLUDE_TEMPLATE_IMPLEMENTATION
#include "AsyncBergerRigoutsosNode.C"
#endif
